{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten,BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, MaxPooling2D,Conv2D\n",
    "from tensorflow.keras.layers import Input,Activation,Add\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import os, cv2\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir=\"data/train\"\n",
    "training_data=[]\n",
    "categories=[\"Male\",\"Female\"]\n",
    "for category in categories:\n",
    "    path=os.path.join(datadir,category)\n",
    "    class_num=categories.index(category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "        img_array=cv2.resize(img_array,(img_size,img_size))\n",
    "        training_data.append([img_array, class_num])\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "y_train=[]\n",
    "for image,gender in training_data:\n",
    "    x_train.append(image)\n",
    "    y_train.append(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.array(x).reshape(-1,img_size,img_size,1)\n",
    "x_train=x_train/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(32,kernel_size=(3, 3),padding = 'same',strides=(1, 1),kernel_regularizer=l2(0.001), activation=\"relu\",input_shape=x_train.shape[1:]))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling2D(pool_size = (2,2) )) \n",
    "model.add(Conv2D(64,kernel_size=(3, 3),padding = 'same',strides=(1, 1),kernel_regularizer=l2(0.001), activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2))  )\n",
    "model.add(Conv2D(128,kernel_size=(3, 3),padding = 'same',strides=(1, 1),kernel_regularizer=l2(0.001), activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling2D(pool_size = (2,2) )) \n",
    "model.add(Conv2D(256,kernel_size=(3, 3),padding = 'same',strides=(1, 1),kernel_regularizer=l2(0.001), activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling2D(pool_size = (2,2) )) \n",
    "model.add(Flatten())\n",
    "model.add( Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add( Dense(1,activation=\"sigmoid\",name='sex_out'))\n",
    "model.compile(loss=[\"binary_crossentropy\"], optimizer=\"Adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 4s 354ms/step - loss: 0.9825 - accuracy: 0.5000 - val_loss: 0.9174 - val_accuracy: 0.5294\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.8904 - accuracy: 0.5135 - val_loss: 0.8542 - val_accuracy: 0.5294\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.8354 - accuracy: 0.5338 - val_loss: 0.8104 - val_accuracy: 0.5294\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.7963 - accuracy: 0.5338 - val_loss: 0.7809 - val_accuracy: 0.5294\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.7726 - accuracy: 0.5338 - val_loss: 0.7618 - val_accuracy: 0.5294\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.7542 - accuracy: 0.5338 - val_loss: 0.7484 - val_accuracy: 0.5294\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.7441 - accuracy: 0.5338 - val_loss: 0.7394 - val_accuracy: 0.5294\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.7353 - accuracy: 0.5338 - val_loss: 0.7334 - val_accuracy: 0.5294\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7271 - accuracy: 0.5338 - val_loss: 0.7278 - val_accuracy: 0.5294\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 4s 361ms/step - loss: 0.7201 - accuracy: 0.5473 - val_loss: 0.7247 - val_accuracy: 0.5294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fa8270ab08>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=16,epochs=50,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "x_test=[]\n",
    "datadir=\"data/test\"\n",
    "categories=[\"Male\",\"Female\"]\n",
    "for category in categories:\n",
    "    path=os.path.join(datadir,category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "        img_array=cv2.resize(img_array,(img_size,img_size))\n",
    "        x_test.append(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=random.shuffle(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=np.array(x).reshape(-1,img_size,img_size,1)\n",
    "x_test=x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165, 80, 80, 1)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165, 1)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=np.round(model.predict(x_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
